---
title: "Prediction Assignment Writeup"
author: "Okan Delibalta"
date: "8/16/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

## Basisc and Data
Work directory for the script is changed below. You may need to edit the line if you want to run the code on your machine or just comment it out. Code below downloads the data, reads it as a csv and cleans up the empty values.

```{r}
library(caret)
library(randomForest)
# you may need to change the setwd line below or just comment it out 
setwd('/home/odelibalta/Study/Coursera/8_PracticalMachineLearning')

# download.file( "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "train.csv", method = "curl" )
trainData <- read.csv( "train.csv", na.strings = c("", "NA", "#DIV/0!") )

# download.file( "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "test.csv", method = "curl" )
testData <- read.csv( "test.csv", na.strings = c("", "NA", "#DIV/0!") )

# Delete columns with all missing values
trainData<- trainData[ , colSums( is.na( trainData) ) == 0 ]
testData <- testData[ , colSums( is.na( testData ) ) == 0 ]

# Get rid of the columns we know are irrelevant to this research
# They happen to be the one after another at the beginning 
# user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window 
trainData <- trainData[ , -c(1:7) ]
testData  <- testData[ , -c(1:7) ]


```

Lets take a look at the data we have so far.

```{r}
dim(trainData)
table(trainData$classe)
```

# PreProcess
## Partition the train set
Recall from the lectures that at the beginning we focus on the training set alone. We are going to make an %80, %20 split for training and validation. Most of the functioanlity we need is included in the caret package.

```{r}

set.seed(323232)
trainSet <- createDataPartition(trainData$classe, p = 0.8, list = FALSE)

train <- trainData[trainSet, ]
validation <- train[-trainSet, ]
```


## Picking our model
If you have not noticed it yet, one of the libraries we have loaded is the randomForest library which we will use for this. We do not have a big dataset so we are shooting for accuracy with selecting randomForest. We will watch out for overfitting in the upcoming sections.


```{r}
rfModel <- randomForest( classe ~ ., data = train, importance = TRUE, ntrees = 10)
```

## Validating the model
Curious to see how accurate we are ? 

```{r}
predict_training <- predict( rfModel, train )
print( confusionMatrix( predict_training, train$classe ) )
```

Model performs well and hits the sweet spot for me. If it was %100 all the way, I would be worried about the out of sample error and overfitting. We will check for those of course but so far it is not as worrisome. 

## Validation on the validation set - our out of sample test 

```{r}
predict_validation <- predict( rfModel, validation )
print( confusionMatrix( predict_validation, validation$classe ) )

```

## Final step - Test set 
```{r}
predict_test <- predict(rfModel, testData)
predict_test
```















